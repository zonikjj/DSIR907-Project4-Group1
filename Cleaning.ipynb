{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f75a65-4b79-4d3e-b8f1-ab7f5ae68a3b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57e92f1-4746-491f-9944-8df68969dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np #used to handle np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352e253c-d530-47ad-9eb7-df29d8baf0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('.\\Project 4\\DSIR907-Project4-Group1/cleaned_debate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a75e4d-1023-493d-b5d0-26b8024211de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9051, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f045cdbb-c31a-4b3b-90bc-285c10d19f77",
   "metadata": {},
   "source": [
    "Below is a list of candidate names that are correctly spelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f01a583-a1d4-4cf6-96aa-f6cb5f870b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "candidate_list = ['Nixon', 'Kennedy', 'Carter', 'Ford', 'Reagan', 'Anderson', 'Mondale', 'Ferraro', 'Bush', 'Dukakis', 'Quayle', 'Bentsen', 'Clinton', 'Bush', 'Perot', 'Gore', 'Stockdale', 'Dole', 'Kemp', 'Lieberman', 'Cheney', 'Kerry', 'Edwards', 'McCain', 'Obama', 'Biden', 'Palin', 'Romney', 'Ryan', 'Trump', 'Pence', 'Kaine', 'Harris']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de03ab-fff1-4dec-8907-8b82c7997fc0",
   "metadata": {},
   "source": [
    "For our purposes, it will be useful to also have a list of some of the moderator's names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a3373b-1b51-4c97-bac6-16a6bfd814d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_list.extend(['warner', 'cronkite', 'Lieberman', 'smith', 'kelly', 'thomas', 'brokaw', 'fowler', \"O'brien\", 'baltimore', 'audience' 'mondale', 'newman', 'david', 'lehrer', 'speakers', 'washington', 'holt', 'wallace', 'moderator',  'schieffer', 'participants', 'moderators', 'chancellor', 'crowley','fleck', 'giannotti', 'farley', 'niven', 'berkley','spivak', 'quijano', 'page', 'hubb', 'mashek','dube'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72281bb-7032-41ad-a270-0b7188dd5b8c",
   "metadata": {},
   "source": [
    "Uncomment the following line to see all the speakers in the debate. This was used to assist in constructing the list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5d608b-c47f-44d7-8c2e-2c6ecf8941f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#raw['Speaker'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735053fd-a37f-48c1-9fab-2d9cb8753c7a",
   "metadata": {},
   "source": [
    "It was found in the course of our algorithm that there was an NaN value, we find it here to deal with it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b30a07-0691-49b9-a82e-c09dfd4c7fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Placeholder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Well, I believe that we did the appropriate t...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Speaker                                               Text  Placeholder\n",
       "6497     NaN   Well, I believe that we did the appropriate t...           25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[raw['Speaker'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca582ef7-16a0-4f3b-a09e-63186b93cd4c",
   "metadata": {},
   "source": [
    "Using the quote below, we find that this was a quote from Clinton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c9598ee-7020-4650-9bc4-285a18f7d09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Well, I believe that we did the appropriate thing under the circumstances. Saddam Hussein is under a U.N. resolution not to threaten his neighbors or threaten his own, repress his own citizens. Unfortunately, a lot of people, have never been as concerned about the Kurds as the United States has tried to be, and we’ve been flying an operation to protect them out of Turkey for many years now. What happened was one of the Turkish, one of the Kurdish leaders invited him to go up north, but we felt since the whole world community had told him not to do it, that once he did it we had to do something. We did not feel that I could commit. I certainly didn’t feel I should commit American troops to throw him out of where he had gone, and that was the only way to do that. So the appropriate thing strategically to do was to reduce his ability to threaten his neighbors. We did that by expanding what’s called the no-fly zone by increasing our allies’ control of the air space now from the Kuwait border to the suburbs of Baghdad. Was it the right thing to do? I believe it was. Is it fully effective? Did it make him withdraw from the north? Well, he does , he has a little bit, and I hope he will continue. We have learned that you give him an inch he’ll take a mile. We had to do something, and even though not all of our allies supported it at first, I think most of them now believe that what we did was an appropriate thing to do.,'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.iloc[6497,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250da08-acdd-40fd-86ee-c54c9e341b58",
   "metadata": {},
   "source": [
    "Since the names from the transcripts are all uppercase, we convert our list to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0fbb384-df70-4dcf-89b4-e90751796da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_list=[candidate.upper() for candidate in candidate_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b8a93-03a1-44e5-8673-e69a6e80a602",
   "metadata": {},
   "source": [
    "We are looking for mispellings of names, as such, we ignore the names we know are spelt correctly. This includes times, years and an occurence of (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c6eb56-2d9a-4335-abef-d534c4bd1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_set = set(candidate_list).union(set(['7','8','9','10','11','1980','1986','(CNN)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f36635-03c4-4ee5-bfc6-ab310b0375ad",
   "metadata": {},
   "source": [
    "The set of values we are considering imputing is the difference between the unique speakers and our `ignore_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3edee3-05b2-4828-8b1b-ef1831fcc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_set = set(raw['Speaker'].unique()) - ignore_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b29acf04-dc8c-44fb-a772-28a12f593938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "impute_set = impute_set -{np.nan} #our code won't work with the \"float\" NaN, so we remove it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c60f6b2-1daf-4cdc-b08a-045204cf9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lev_dist_fast(str1,str2):\n",
    "    \"\"\"This is an implementation of Levenshtein distance, the distance between two strings is the minimal number of\n",
    "    insertions, deletions and substitutions required to go from one string to the other.\n",
    "    \"\"\"\n",
    "    #initialize a dataframe with characters of the strings on the axes and an extra empty row/column index\n",
    "    dist_data = pd.DataFrame(index=list(' '+str1), columns = list(' '+str2))  \n",
    "    dist_data.fillna(0, inplace=True) #Fill the na values with zero.\n",
    "    #print(dist_data) #used to check that the code ran properly\n",
    "    \n",
    "    #record the lengths of our strings for use below.\n",
    "    n=len(str2)\n",
    "    m=len(str1)\n",
    "    \n",
    "    #Initialize the first column of the dataframe, the indices are 1 to m+1 since [0,0] is already 0\n",
    "    for i in range(1, m+1):\n",
    "        dist_data.iloc[i,0] = i\n",
    "    \n",
    "    #Initialize the first row of the dataframe similarly.\n",
    "    for j in range(1, n+1):\n",
    "        dist_data.iloc[0,j] = j\n",
    "    \n",
    "    #Loop over the entries of the dataframe\n",
    "    for j in range(1, n+1): #top to bottom\n",
    "        for i in range(1, m+1): # but first left to right\n",
    "            \n",
    "            #If the characters of the string are the same, it costs nothing to substitute\n",
    "            if str1[i-1] == str2[j-1]: #due to extra padding, indices are offset by 1.\n",
    "                substitutionCost = 0\n",
    "            else:\n",
    "                substitutionCost = 1 #if the strings aren't the same it costs 1 to substitute\n",
    "            \n",
    "            dist_data.iloc[i, j] = min(dist_data.iloc[i-1][j] +1, #deletion\n",
    "                                       dist_data.iloc[i, j-1] +1, #insertion\n",
    "                                       dist_data.iloc[i-1,j-1]+substitutionCost) #substitution\n",
    "            \n",
    "    #print(dist_data) #if you want to see the resulting dataframe, uncomment this print statement.   \n",
    "    return dist_data.iloc[-1,-1] \n",
    "#The dictionary computes the Levenstein distance between subwords str1[:i] str2[:j], we are only interested in \n",
    "#the distance between str1 and str2 as a whole, the last entry of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0a07dc-810b-4040-a345-4476f6916f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_dist_fast('kitten', 'sitting') #this cell is purely for testing purposes. Change the strings and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61e88266-ded5-4dce-a52f-c2636c601d68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[*]SCHIEFFER', 'SCHIEFFER') 3\n",
      "('MR.FORD', 'FORD') 3\n",
      "('[*]CROWLEY', 'CROWLEY') 3\n",
      "('ROMNEHY', 'ROMNEY') 1\n",
      "('REAGAV', 'REAGAN') 1\n",
      "('OBAM', 'OBAMA') 1\n",
      "('SM1TH', 'SMITH') 1\n",
      "('KONDRACKE', 'MONDALE') 4\n",
      "('JOHNSON', 'CLINTON') 4\n",
      "('OREGONIAN', 'REAGAN') 5\n"
     ]
    }
   ],
   "source": [
    "speaker_score_dict={}\n",
    "vetted_set = set(candidate_list) #this is the set of correctly spelled names.\n",
    "\n",
    "for speaker in impute_set:\n",
    "    distance=20 #initialize the distance to be larger than the length of any of the names\n",
    "    best_candidate='' #initialize best candidate\n",
    "    for candidate in vetted_set:\n",
    "        new_dist=lev_dist_fast(speaker,candidate) #compare speakers with correctly spelled names.\n",
    "        \n",
    "        #the best candidate for who the speaker is should be the word of minimal distance.\n",
    "        if(new_dist<distance):\n",
    "            distance=new_dist\n",
    "            best_candidate=candidate\n",
    "            \n",
    "    #at this point, we have a best_candidate for who the speaker is\n",
    "    #append this to a dictionary with key the distance from the speaker\n",
    "    if(distance in speaker_score_dict.keys()):\n",
    "        speaker_score_dict[distance].append((speaker, best_candidate)) #If the speaker's distance is already in the dictionary, add the pair of speakers to the dictionary's list.\n",
    "    else:\n",
    "        speaker_score_dict[distance]=[]\n",
    "        speaker_score_dict[distance].append((speaker, best_candidate)) #Otherwise initialize an empty list and add the speaker, candidate pair.\n",
    "        \n",
    "#We're not done yet, the following simple sanity check helps a lot!        \n",
    "\n",
    "final_dict={} #initialize our final dictionary\n",
    "for i in speaker_score_dict.keys(): #Loop over our earlier dictionary\n",
    "    \n",
    "    #Check if the speaker only occurred in debates where their candidate identity also occurred.\n",
    "    #We are assuming few typos and that mispelled names occur with the correct name in the same transcript.\n",
    "    \n",
    "    for pair in speaker_score_dict[i]: \n",
    "        typo_loc = raw[raw['Speaker']==pair[0]].Placeholder.unique()\n",
    "        fix_loc = raw[raw['Speaker']==pair[1]].Placeholder.unique()\n",
    "        if(set(typo_loc).issubset(set(fix_loc))): #the occurances of the typo only happen when the candidate name is also in the transcript.\n",
    "            print(pair,i) #we print the pair together with their distance for a final eyeballing.\n",
    "            \n",
    "            #our final dictionary is any pair not filtered out by this sanity check.\n",
    "            final_dict[pair[0]]=pair[1]\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d12cc-7d11-4f8e-afee-4da2cc699cc9",
   "metadata": {},
   "source": [
    "From here, it is pretty claer which of these names are typos and which are simply two names which happen to share some letters. The following names were reporters at these debates\n",
    "\n",
    "Kondracke, (Pamela) Johnson, and Dube are all journalists. Oregonian was the title of Hilliard, a reporter for the paper, when he first asked a question.\n",
    "\n",
    "<b>Note:</b> While these names cannot distinguish between Hillary and Bill Clinton nor George Bush and George H. W. Bush, these names being imputed to the classes Republican, Democrat, and Other, mean the distinction shouldn't matter. Another minor note is that Ross Perot, while he ran as an independent, will be classified as a Republican for the purposes of our algorithm as he was a right-leaning candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809ebec-a413-4916-8f3c-ba018bf3b580",
   "metadata": {},
   "source": [
    "Anyways, we delete the names which were correct from our dictionary and update Oregonian to Hilliard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965a0561-9bce-450e-86a3-d0584636a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_dict['KONDRACKE']\n",
    "del final_dict['JOHNSON']\n",
    "final_dict['OREGONIAN']='HILLIARD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25448fa3-571b-4071-add2-c7e383dc5eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[*]SCHIEFFER': 'SCHIEFFER',\n",
       " 'MR.FORD': 'FORD',\n",
       " '[*]CROWLEY': 'CROWLEY',\n",
       " 'ROMNEHY': 'ROMNEY',\n",
       " 'REAGAV': 'REAGAN',\n",
       " 'OBAM': 'OBAMA',\n",
       " 'SM1TH': 'SMITH',\n",
       " 'OREGONIAN': 'HILLIARD'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce766a94-05c6-408f-b506-1b653157992a",
   "metadata": {},
   "source": [
    "In sum, there were 8 typos which we picked up from our algorithm. Since this is in a dictionary, we can simply call a .replace on the raw data to update all the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0401bf16-c239-4f54-aa53-300e7232be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_speakers = raw.replace(final_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d42da-10b2-40cd-8f59-a2de9108c4c5",
   "metadata": {},
   "source": [
    "However, we are not done yet. At least two anomalies remain. The `NaN` speaker needs to be updated to `'CLINTON'`. Additionally, there was a speaker named `W` who needs to be identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eccda7e-d513-410c-ac16-76e2f2529eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Senator Quayle, all of us in our lifetime encounter an experience that helps shapes our adult philosophy in some form or another. Could you describe for this audience tonight what experience you may have had, and how it shaped our political philosophy?,'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[raw['Speaker']=='W'].Text[7810]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072fcbe6-61d0-42bd-897d-55ab9ec03095",
   "metadata": {},
   "source": [
    "This quote from `W` makes clear that they are likely a reporter of some sort. Checking the speakers in debate 33 yields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99c75472-a046-4430-acbb-3d62160e34f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WOODRUFF', 'QUAYLE', 'BENTSEN', 'MARGOLIS', 'BROKAW', '1986',\n",
       "       'HUME', 'W'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[raw['Placeholder']==33].Speaker.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb558e-856e-4d5b-a548-526e7e54b530",
   "metadata": {},
   "source": [
    "So, `W` is likely `WOODRUFF` and we impute this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72734630-cba5-4f5c-b5b4-e34df1879227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_speakers = cleaned_speakers.replace('W','WOODRUFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3408d24-fe31-43d6-a4c2-706d118e7cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_speakers = cleaned_speakers.fillna('CLINTON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a2647-f39c-4fd8-b5cc-0b6d3423c377",
   "metadata": {},
   "source": [
    "This brings us to a few other odd Speaker values:\n",
    "\n",
    "1) `1986`\n",
    "2) `1980`\n",
    "3) `(CNN)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06739ae1-ded0-4d38-950c-ac5a06b503c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Placeholder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>1980</td>\n",
       "      <td>He would never reduce benefits. And of course...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Speaker                                               Text  Placeholder\n",
       "8226    1980   He would never reduce benefits. And of course...           37"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers[cleaned_speakers['Speaker']=='1980']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50bdea1-a93f-4bdc-bdba-b0934cfa6871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speaker                                                  MONDALE\n",
       "Text            Well, that’s exactly the commitment that was ...\n",
       "Placeholder                                                   37\n",
       "Name: 8225, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers.iloc[8225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6571d62d-99af-408e-86bd-c430c94b9906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' He would never reduce benefits. And of course, what happened right after the election is they proposed to cut Social Security benefits by 25 percent — reducing the adjustment for inflation, cutting out minimum benefits for the poorest on Social Security, removing educational benefits for dependents whose widows were trying — with widows trying to get them through college. Everybody remembers that; people know what happened., There’s a difference. I have fought for Social Security and Medicare and for things to help people who are vulnerable all my life, and I will do it as President of the United States., MS.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers.iloc[8226].Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22f2ee-990c-4629-bfc9-4f0603fc4d00",
   "metadata": {},
   "source": [
    "Here we see that 1980 was likely a part of a statement made by Mondale. So, we replace this in our dataframe as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e582937c-db00-4a66-8304-e393baad1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_speakers = cleaned_speakers.replace('1980', 'MONDALE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8d1ae-43f4-4c05-973d-11e3775ba15d",
   "metadata": {},
   "source": [
    "Now to figure out 1986."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c91fc6ea-a93d-4bc8-a68c-b7fc085d30ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Placeholder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7692</th>\n",
       "      <td>1986</td>\n",
       "      <td>six million working poor families got off the...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Speaker                                               Text  Placeholder\n",
       "7692    1986   six million working poor families got off the...           33"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers[cleaned_speakers['Speaker']=='1986']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "968a75db-322d-4774-9e59-3425a9dc9045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' six million working poor families got off the payroll; six million people are off the taxpaying payrolls because of that tax reform, and they are keeping the tax money there. To help the poor, we’ll have a commitment to the programs and those programs will go on. And we are spending more in poverty programs today than we were in 1981 – that is a fact. The poverty program we are going to concentrate on is creating jobs and opportunities, so that everyone will have the opportunities that they want.] (Scattered applause),'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers[cleaned_speakers['Speaker']=='1986'].Text[7692]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea26aa1b-35a6-4387-900e-52ff64c008f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speaker                                                   QUAYLE\n",
       "Text            I have met with those people, and I met with ...\n",
       "Placeholder                                                   33\n",
       "Name: 7691, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers.iloc[7691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "323b4203-3df3-47ad-a3d7-2cb145266aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I have met with those people, and I met with them in Fort Wayne, Indiana, at a food bank. You may be surprised, Tom, they didn’t ask me those questions on those votes, because they were glad that I took time out of my schedule to go down and to talk about how we are going to get a food bank going and making sure that a food bank goes in Fort Wayne, Indiana. And I have a very good record and a commitment to the poor, to those that don’t have a family, that want to have a family. This administration, and a George Bush administration, will be committed to eradicating poverty. Poverty hasn’t gone up in this administration; it hasn’t gone down much either, and that means we have a challenge ahead of us. But let me tell you something, what we have done for the poor. What we have done for the poor is that we in fact – the homeless bill, the McKinney Act, which is the major piece of legislation that deals with homeless – the Congress has cut the funding that the administration has recommended. The poor and the poverty – the biggest thing that we have done for poverty in America is the Tax Simplification Act of'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers.iloc[7691].Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22363b3-470a-4e76-ada9-cbb16bbe7288",
   "metadata": {},
   "source": [
    "From here, we see that 1986 is likely a continuation of a statement by Quayle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1de1a11-65b0-40ca-bc6d-01602ef590f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_speakers = cleaned_speakers.replace('1986', 'QUAYLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0b4e136-1765-4881-a80e-f6ac5b9a93b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Placeholder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>WOODRUFF</td>\n",
       "      <td>On behalf of the Commission on Presidential D...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7670</th>\n",
       "      <td>WOODRUFF</td>\n",
       "      <td>For the next 90 minutes we will be questionin...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>WOODRUFF</td>\n",
       "      <td>Your leader in the Senate Bob Dole said that ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7672</th>\n",
       "      <td>QUAYLE</td>\n",
       "      <td>The question goes to whether I am qualified t...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7673</th>\n",
       "      <td>WOODRUFF</td>\n",
       "      <td>Senator Bentsen – I’m going to interrupt at t...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>WOODRUFF</td>\n",
       "      <td>We’re sorry about that if that’s the case. Th...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>QUAYLE</td>\n",
       "      <td>Bigger government, higher taxes. They’ve alwa...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>WOODRUFF</td>\n",
       "      <td>Senator Bentsen, your closing statement.,</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>BENTSEN</td>\n",
       "      <td>In just 34 days, America will elect new leade...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821</th>\n",
       "      <td>WOODRUFF</td>\n",
       "      <td>Thank you both, thank you., © COPYRIGHT 2020 ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Speaker                                               Text  Placeholder\n",
       "7669  WOODRUFF   On behalf of the Commission on Presidential D...           33\n",
       "7670  WOODRUFF   For the next 90 minutes we will be questionin...           33\n",
       "7671  WOODRUFF   Your leader in the Senate Bob Dole said that ...           33\n",
       "7672    QUAYLE   The question goes to whether I am qualified t...           33\n",
       "7673  WOODRUFF   Senator Bentsen – I’m going to interrupt at t...           33\n",
       "...        ...                                                ...          ...\n",
       "7817  WOODRUFF   We’re sorry about that if that’s the case. Th...           33\n",
       "7818    QUAYLE   Bigger government, higher taxes. They’ve alwa...           33\n",
       "7819  WOODRUFF          Senator Bentsen, your closing statement.,           33\n",
       "7820   BENTSEN   In just 34 days, America will elect new leade...           33\n",
       "7821  WOODRUFF   Thank you both, thank you., © COPYRIGHT 2020 ...           33\n",
       "\n",
       "[153 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers[cleaned_speakers['Placeholder']==33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48cffdba-4edf-4888-8bcc-5b64298a77a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Mr. Perot, you’ve talked about going to Washington to do what the people who run this country want you to do. But it is the president’s duty to lead, and often lead alone. How can you lead if you are forever seeking consensus before you act?,'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers[cleaned_speakers['Speaker']=='(CNN)'].Text[6686]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97834faa-ac61-4c59-8a2c-8a554307dd75",
   "metadata": {},
   "source": [
    "(CNN) is likely another moderator, so we impute it to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67035530-0580-4424-9663-d0559f754c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_speakers = cleaned_speakers.replace('(CNN)', 'MODERATOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2649ddd6-29a5-4ad5-b8b7-5c84526d5d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Placeholder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Speaker, Text, Placeholder]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_speakers[cleaned_speakers['Speaker']=='SM1TH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eedc7e43-ee6f-4f67-82c1-d0aa6b5a6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_speakers.to_csv('cleaned_candidates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e733db3-8485-4804-aa7a-0a7d39e11127",
   "metadata": {},
   "source": [
    "The code below is a slower function for computing the Levenshtein Distance between two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074b4c1-7dbf-41bb-bc5f-4061b57866ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lev_dist(string1,string2):\n",
    "    #print('processing')\n",
    "    string1=string1.lower()\n",
    "    string2=string2.lower()\n",
    "    if(string1==''):\n",
    "        return len(string2)\n",
    "    elif(string2==''):\n",
    "        return len(string1)\n",
    "    elif(string1[0]==string2[0]):\n",
    "        return lev_dist(string1[1:],string2[1:])\n",
    "    else:\n",
    "        return 1+min(lev_dist(string1[1:],string2),lev_dist(string1, string2[1:]), lev_dist(string1[1:],string2[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8561af-3bb7-4270-a6bb-38514598c251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
